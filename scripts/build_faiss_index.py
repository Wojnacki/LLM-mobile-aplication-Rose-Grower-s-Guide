import json
from pathlib import Path

import faiss
from sentence_transformers import SentenceTransformer


# ===== KONFIGURACJA =====
CHUNKS_FILE = Path("knowledge/chunks/poradnik_pielegnacji_roz_chunks_fixed.jsonl")
INDEX_FILE = Path("knowledge/faiss/rose_index.faiss")
META_FILE = Path("knowledge/faiss/rose_chunks_meta.json")

MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
# ========================


def load_chunks(path):
    with path.open(encoding="utf-8") as f:
        return [json.loads(line) for line in f]


def main():
    if not CHUNKS_FILE.exists():
        raise FileNotFoundError(f"âŒ Brak pliku: {CHUNKS_FILE}")

    INDEX_FILE.parent.mkdir(parents=True, exist_ok=True)

    print("ğŸ”¹ Åadowanie chunkÃ³w...")
    chunks = load_chunks(CHUNKS_FILE)
    texts = [c["text"] for c in chunks]

    print(f"ğŸ”¹ ChunkÃ³w: {len(texts)}")

    print("ğŸ”¹ Åadowanie modelu embeddingÃ³w...")
    model = SentenceTransformer(MODEL_NAME)

    print("ğŸ”¹ Tworzenie embeddingÃ³w...")
    embeddings = model.encode(
        texts,
        convert_to_numpy=True,
        show_progress_bar=True,
        normalize_embeddings=True
    )

    dim = embeddings.shape[1]
    print(f"ğŸ”¹ Wymiar embeddingÃ³w: {dim}")

    print("ğŸ”¹ Budowa indeksu FAISS...")
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)

    faiss.write_index(index, str(INDEX_FILE))

    with META_FILE.open("w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False, indent=2)

    print("\nâœ… FAISS index gotowy")
    print(f"ğŸ“¦ Index: {INDEX_FILE}")
    print(f"ğŸ“„ Meta:  {META_FILE}")


if __name__ == "__main__":
    main()
